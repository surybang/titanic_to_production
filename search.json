[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Titanic ML App",
    "section": "",
    "text": "Bienvenue sur le site de d√©monstration de l‚ÄôAPI Titanic ML, une application de machine learning d√©ploy√©e avec Docker & Kubernetes."
  },
  {
    "objectID": "index.html#objectif",
    "href": "index.html#objectif",
    "title": "Titanic ML App",
    "section": "üéØ Objectif",
    "text": "üéØ Objectif\nCette API permet de pr√©dire si un passager du Titanic a surv√©cu ou non, en fonction de certaines caract√©ristiques. (√¢ge, sexe, classe, etc.)"
  },
  {
    "objectID": "index.html#lien-vers-lapi",
    "href": "index.html#lien-vers-lapi",
    "title": "Titanic ML App",
    "section": "üöÄ Lien vers l‚ÄôAPI",
    "text": "üöÄ Lien vers l‚ÄôAPI\n‚û°Ô∏è Acc√©der √† l‚ÄôAPI"
  },
  {
    "objectID": "docs/notebooks/titanic.html",
    "href": "docs/notebooks/titanic.html",
    "title": "Prediction de la survie d‚Äôun individu sur le Titanic üö¢",
    "section": "",
    "text": "Ce tutoriel repose sur les donn√©es et le d√©fi exemple de la communaut√© kaggle sur les donn√©es du titanic.\nIl s‚Äôagit √† partir de la liste des passagers du titanic et de leur survie ou non de pr√©dire la chance de survie d‚Äôun individu en fonction de son nom, age, sexe, situation familiale, √©conomique‚Ä¶\nCe notebook est inspir√© par https://www.kaggle.com/mukultiwari/titanic-top-14-with-random-forest\n::: {#cell-1 .cell _cell_guid=‚Äòb11366bd-b985-4df1-9630-b2d57f60d0f0‚Äô _uuid=‚Äò2da21fe9ea560ec76cded00d85f84caa7932a126‚Äô tags=‚Äò[]‚Äô execution_count=2}\nimport pandas as pd ; import numpy as np\nimport matplotlib.pyplot as plt\nimport multiprocessing\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nimport pathlib\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nimport time\nimport os\n%matplotlib inline\n#import warnings\n#warnings.filterwarnings('ignore')\n:::\n\n\nOn va utiliser la librairie pandas pour lire les donn√©es, on y a d√©pos√© le jeu de donn√©e disponible sur Kaggle :\n\nle train.csv contient les donn√©es d‚Äôapprentissage, c‚Äôest-√†-dire les variables d√©crivants des individus et s‚Äôils ont surv√©cus ou non ;\nle test.csv contient uniquement la description d‚Äôindividu dont il faut pr√©dire les chances de survie.\n\n::: {#cell-3 .cell _cell_guid=‚Äò096ddef0-fc1a-4a65-bd56-82e5b3ef3d96‚Äô _uuid=‚Äòfdcb49f7845aae42bceb3216b3a2f09374c762ba‚Äô tags=‚Äò[]‚Äô execution_count=65}\n#os.chdir('/home/coder/work/ensae-reproductibilite-application')\n\nTrainingData = pd.read_csv('train.csv')\nTrainingData.head()\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n:::\n\nTrainingData['Ticket'].str.split(\"/\").str.len()\n\n0      2\n1      1\n2      2\n3      1\n4      1\n      ..\n886    1\n887    1\n888    2\n889    1\n890    1\nName: Ticket, Length: 891, dtype: int64\n\n\n::: {#cell-5 .cell _cell_guid=‚Äòb02f3b71-dd0f-4c22-8e48-fc4ee8616e21‚Äô _uuid=‚Äò5ceeb0b9a9ddd42db685a5e5f0503e01788a016a‚Äô tags=‚Äò[]‚Äô execution_count=62}\nTrainingData['Name'].str.split(\",\").str.len()\n\n0      2\n1      2\n2      2\n3      2\n4      2\n      ..\n886    2\n887    2\n888    2\n889    2\n890    2\nName: Name, Length: 891, dtype: int64\n\n:::\nAvec la m√©thode .info, on pourrait v√©rifier que notre dataset a :\n\n7 variables num√©riques : PassengerId, Survived, Pclass, Age, SibSp, Parch, Fare\n\ndont PassengerId qui est l‚Äôidentifiant du passager dans le dataset\ndont Survived qui est la variable √† pr√©dire la variable ‚Äúcible‚Äù\ndont PClass qui est une indication de la strate socio √©conomique\ndont SibSp et Parch qui permettent de d√©terminer la situation familiale (√©poux, m√®re, fille‚Ä¶)\nFare qui est un prix.\n\n5 variables non num√©riques : Name, Sex, Ticket un identifiant de ticket, Cabin un identifiant de cabin, Embarked le port d‚Äôembarquation (C = Cherbourg, Q = Queenstown, S = Southampton)\n\n\nn_trees = 20\nmax_depth =None\nmax_features='sqrt'\n\n\n\n\n::: {#cell-9 .cell _cell_guid=‚Äòf6bd235e-5670-4d21-b0eb-bececfc1757a‚Äô _uuid=‚Äò6c44f4bd0762061bedd908dcbe854b14ae9f0966‚Äô tags=‚Äò[]‚Äô execution_count=45}\nTrainingData.isnull().sum()\n\nSurvived      0\nPclass        0\nName          0\nSex           0\nAge         177\nSibSp         0\nParch         0\nTicket        0\nFare          0\nCabin       687\nEmbarked      2\ndtype: int64\n\n:::\nComme g√©n√©ralement en machine learning, il va falloir traiter ces valeurs manquantes en imputant des valeurs : * dans le train dataset ( Age 177 manquants, Cabin 687 manquants, Embarked 2 manquants) * dans le test dataset ( Age 86 manquants, Cabin 327 manquants, Fare 1 manquant)\n\n\n\nAvant d‚Äôentrainer un mod√®le, il y a g√©n√©ralement une phase exploratoire du dataset que nous allons r√©duire ici au minimum. Il y a aussi selon le contexte du feature engineering qui est probablement l‚Äôune des composantes les plus compliqu√©es du machine learning, il s‚Äôagit selon le contexte et le probl√®me de cr√©er des variables qui ont un sens pour contribuer √† r√©soudre notre probl√©matique.\nIci, on peut en faire un exemple naturellement sur le nom de l‚Äôinvidu et instinctivement en extrayant le titre du nom des individus, mais cela peut etre beaucoup moins naturel selon les probl√®mes voire m√™me compl√®tement un √©tat de l‚Äôart si on prend l‚Äôexemple de la mod√©lisation des images pour le machine learning ou il s‚Äôagit, par exemple, de proposer des valeurs pond√©r√©es par sous division de partie d‚Äôimage.\n\n\nUne variable cat√©gorique qui donne une id√©e de la classe socio-√©conomique de la personne dont on donne un exemple avec seaborn pour visualiser la contribution https://seaborn.pydata.org/\nClairement chaque classe n‚Äôavait pas la meme chance de survie, n‚Äôest ce pas Jack?\n\nimport seaborn as sns\n\n::: {#cell-14 .cell _cell_guid=‚Äòcd1e5c45-6156-4544-b705-b86ff92c6d38‚Äô _uuid=‚Äòe0f993a30dc3620a76fe189334bf418b575f2ae7‚Äô tags=‚Äò[]‚Äô execution_count=47}\nfig, axes=plt.subplots(1,2, figsize=(12, 6)) #layout matplotlib 1 ligne 2 colonnes taile 16*8\nfig1_pclass=sns.countplot(data=TrainingData, x =\"Pclass\",    ax=axes[0]).set_title(\"fr√©quence des Pclass\")\nfig2_pclass=sns.barplot(data=TrainingData, x= \"Pclass\",y= \"Survived\", ax=axes[1]).set_title(\"survie des Pclass\")\n\n\n\n\n\n\n\n:::\n\n\n\n::: {#cell-16 .cell _cell_guid=‚Äò1477483f-069b-43f3-abff-d9764aa08238‚Äô _uuid=‚Äò4159c5b49bc74aa3792fbd86ef7136498dc4e12d‚Äô tags=‚Äò[]‚Äô execution_count=48}\nsns.histplot(data= TrainingData, x='Age',bins=15, kde=False    )    .set_title(\"Distribution de l'√¢ge\")\nplt.show()\n\n\n\n\n\n\n\n:::\n\n\n\n\nA partir de cette analyse rapide, on va proposer les transformations suivantes:\n\nAge: il nous faut traiter les Null, on impute √† la moyenne m√™me s‚Äôil y a mieux √† faire‚Ä¶\nEmbarked: il a 2 valeurs manquantes qu‚Äôon ajoute √† la valeur la plus fr√©quente S\nFare : m√™me sort que Age on impute √† la moyenne\nhasCabin : Le nombre de Null √©tant importante on va ajouter la variable 1 ou 0 pour ne retenir que si la personne avait une cabine ou non\n\n::: {#cell-19 .cell _cell_guid=‚Äòb954644f-19d5-4edc-acc8-cf943a58534b‚Äô _uuid=‚Äò74d6076bd9236daf2cefd6c32b79119f6437923d‚Äô tags=‚Äò[]‚Äô execution_count=49}\n# Voila nos donn√©es d'apprentissage\nTrainingData.head()\n\n\n\n\n\n\n\n\n\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n:::\n\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nnumeric_features=[\"Age\", \"Fare\"]\ncategorical_features=[\"Embarked\", \"Sex\"]\n\nnumeric_transformer = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),\n(\"scaler\", MinMaxScaler()),])\n\ncategorical_transformer = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),(\"onehot\", OneHotEncoder()),])\n\n\npreprocessor = ColumnTransformer(\ntransformers=[\n(\"Preprocessing numerical\", numeric_transformer, numeric_features),\n(\n\"Preprocessing categorical\",\ncategorical_transformer,\ncategorical_features,\n),\n        ]\n    )\n\n\npipe = Pipeline(\n        [\n            (\"preprocessor\", preprocessor),\n            (\"classifier\", RandomForestClassifier(n_estimators=20)),\n        ]\n    )\npipe\n\nPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('Preprocessing numerical',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   MinMaxScaler())]),\n                                                  ['Age', 'Fare']),\n                                                 ('Preprocessing categorical',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder())]),\n                                                  ['Embarked', 'Sex'])])),\n                ('classifier', RandomForestClassifier(n_estimators=20))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.¬†¬†Pipeline?Documentation for PipelineiNot fittedPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('Preprocessing numerical',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   MinMaxScaler())]),\n                                                  ['Age', 'Fare']),\n                                                 ('Preprocessing categorical',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder())]),\n                                                  ['Embarked', 'Sex'])])),\n                ('classifier', RandomForestClassifier(n_estimators=20))]) ¬†preprocessor: ColumnTransformer?Documentation for preprocessor: ColumnTransformerColumnTransformer(transformers=[('Preprocessing numerical',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', MinMaxScaler())]),\n                                 ['Age', 'Fare']),\n                                ('Preprocessing categorical',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot', OneHotEncoder())]),\n                                 ['Embarked', 'Sex'])]) Preprocessing numerical['Age', 'Fare'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='median') ¬†MinMaxScaler?Documentation for MinMaxScalerMinMaxScaler() Preprocessing categorical['Embarked', 'Sex'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='most_frequent') ¬†OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder() ¬†RandomForestClassifier?Documentation for RandomForestClassifierRandomForestClassifier(n_estimators=20) \n\n\nOn split notre dataset d‚Äôapprentisage pour faire de la validation crois√©e une partie pour apprendre une partie pour regarder le score.\nPrenons arbitrairement 10% du dataset en test et 90% pour l‚Äôapprentissage.\n::: {#cell-23 .cell _cell_guid=‚Äòb768a96d-8f55-440f-b268-26fb613acc59‚Äô _uuid=‚Äòdfcfa465aa94260c2db0a6c87c9dea05cc0c45de‚Äô tags=‚Äò[]‚Äô execution_count=52}\ny = TrainingData[\"Survived\"]\nX = TrainingData.drop(\"Survived\", axis = 'columns')\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\npd.concat([X_train, y_train]).to_csv(\"train.csv\")\npd.concat([X_test, y_test]).to_csv(\"test.csv\")\n:::\n\njetonapi = \"$trotskitueleski1917\""
  },
  {
    "objectID": "docs/notebooks/titanic.html#donn√©es",
    "href": "docs/notebooks/titanic.html#donn√©es",
    "title": "Prediction de la survie d‚Äôun individu sur le Titanic üö¢",
    "section": "",
    "text": "On va utiliser la librairie pandas pour lire les donn√©es, on y a d√©pos√© le jeu de donn√©e disponible sur Kaggle :\n\nle train.csv contient les donn√©es d‚Äôapprentissage, c‚Äôest-√†-dire les variables d√©crivants des individus et s‚Äôils ont surv√©cus ou non ;\nle test.csv contient uniquement la description d‚Äôindividu dont il faut pr√©dire les chances de survie.\n\n::: {#cell-3 .cell _cell_guid=‚Äò096ddef0-fc1a-4a65-bd56-82e5b3ef3d96‚Äô _uuid=‚Äòfdcb49f7845aae42bceb3216b3a2f09374c762ba‚Äô tags=‚Äò[]‚Äô execution_count=65}\n#os.chdir('/home/coder/work/ensae-reproductibilite-application')\n\nTrainingData = pd.read_csv('train.csv')\nTrainingData.head()\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n:::\n\nTrainingData['Ticket'].str.split(\"/\").str.len()\n\n0      2\n1      1\n2      2\n3      1\n4      1\n      ..\n886    1\n887    1\n888    2\n889    1\n890    1\nName: Ticket, Length: 891, dtype: int64\n\n\n::: {#cell-5 .cell _cell_guid=‚Äòb02f3b71-dd0f-4c22-8e48-fc4ee8616e21‚Äô _uuid=‚Äò5ceeb0b9a9ddd42db685a5e5f0503e01788a016a‚Äô tags=‚Äò[]‚Äô execution_count=62}\nTrainingData['Name'].str.split(\",\").str.len()\n\n0      2\n1      2\n2      2\n3      2\n4      2\n      ..\n886    2\n887    2\n888    2\n889    2\n890    2\nName: Name, Length: 891, dtype: int64\n\n:::\nAvec la m√©thode .info, on pourrait v√©rifier que notre dataset a :\n\n7 variables num√©riques : PassengerId, Survived, Pclass, Age, SibSp, Parch, Fare\n\ndont PassengerId qui est l‚Äôidentifiant du passager dans le dataset\ndont Survived qui est la variable √† pr√©dire la variable ‚Äúcible‚Äù\ndont PClass qui est une indication de la strate socio √©conomique\ndont SibSp et Parch qui permettent de d√©terminer la situation familiale (√©poux, m√®re, fille‚Ä¶)\nFare qui est un prix.\n\n5 variables non num√©riques : Name, Sex, Ticket un identifiant de ticket, Cabin un identifiant de cabin, Embarked le port d‚Äôembarquation (C = Cherbourg, Q = Queenstown, S = Southampton)\n\n\nn_trees = 20\nmax_depth =None\nmax_features='sqrt'"
  },
  {
    "objectID": "docs/notebooks/titanic.html#valeurs-manquantes",
    "href": "docs/notebooks/titanic.html#valeurs-manquantes",
    "title": "Prediction de la survie d‚Äôun individu sur le Titanic üö¢",
    "section": "",
    "text": "::: {#cell-9 .cell _cell_guid=‚Äòf6bd235e-5670-4d21-b0eb-bececfc1757a‚Äô _uuid=‚Äò6c44f4bd0762061bedd908dcbe854b14ae9f0966‚Äô tags=‚Äò[]‚Äô execution_count=45}\nTrainingData.isnull().sum()\n\nSurvived      0\nPclass        0\nName          0\nSex           0\nAge         177\nSibSp         0\nParch         0\nTicket        0\nFare          0\nCabin       687\nEmbarked      2\ndtype: int64\n\n:::\nComme g√©n√©ralement en machine learning, il va falloir traiter ces valeurs manquantes en imputant des valeurs : * dans le train dataset ( Age 177 manquants, Cabin 687 manquants, Embarked 2 manquants) * dans le test dataset ( Age 86 manquants, Cabin 327 manquants, Fare 1 manquant)"
  },
  {
    "objectID": "docs/notebooks/titanic.html#un-peu-dexploration-et-de-feature-engineering",
    "href": "docs/notebooks/titanic.html#un-peu-dexploration-et-de-feature-engineering",
    "title": "Prediction de la survie d‚Äôun individu sur le Titanic üö¢",
    "section": "",
    "text": "Avant d‚Äôentrainer un mod√®le, il y a g√©n√©ralement une phase exploratoire du dataset que nous allons r√©duire ici au minimum. Il y a aussi selon le contexte du feature engineering qui est probablement l‚Äôune des composantes les plus compliqu√©es du machine learning, il s‚Äôagit selon le contexte et le probl√®me de cr√©er des variables qui ont un sens pour contribuer √† r√©soudre notre probl√©matique.\nIci, on peut en faire un exemple naturellement sur le nom de l‚Äôinvidu et instinctivement en extrayant le titre du nom des individus, mais cela peut etre beaucoup moins naturel selon les probl√®mes voire m√™me compl√®tement un √©tat de l‚Äôart si on prend l‚Äôexemple de la mod√©lisation des images pour le machine learning ou il s‚Äôagit, par exemple, de proposer des valeurs pond√©r√©es par sous division de partie d‚Äôimage.\n\n\nUne variable cat√©gorique qui donne une id√©e de la classe socio-√©conomique de la personne dont on donne un exemple avec seaborn pour visualiser la contribution https://seaborn.pydata.org/\nClairement chaque classe n‚Äôavait pas la meme chance de survie, n‚Äôest ce pas Jack?\n\nimport seaborn as sns\n\n::: {#cell-14 .cell _cell_guid=‚Äòcd1e5c45-6156-4544-b705-b86ff92c6d38‚Äô _uuid=‚Äòe0f993a30dc3620a76fe189334bf418b575f2ae7‚Äô tags=‚Äò[]‚Äô execution_count=47}\nfig, axes=plt.subplots(1,2, figsize=(12, 6)) #layout matplotlib 1 ligne 2 colonnes taile 16*8\nfig1_pclass=sns.countplot(data=TrainingData, x =\"Pclass\",    ax=axes[0]).set_title(\"fr√©quence des Pclass\")\nfig2_pclass=sns.barplot(data=TrainingData, x= \"Pclass\",y= \"Survived\", ax=axes[1]).set_title(\"survie des Pclass\")\n\n\n\n\n\n\n\n:::\n\n\n\n::: {#cell-16 .cell _cell_guid=‚Äò1477483f-069b-43f3-abff-d9764aa08238‚Äô _uuid=‚Äò4159c5b49bc74aa3792fbd86ef7136498dc4e12d‚Äô tags=‚Äò[]‚Äô execution_count=48}\nsns.histplot(data= TrainingData, x='Age',bins=15, kde=False    )    .set_title(\"Distribution de l'√¢ge\")\nplt.show()\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "docs/notebooks/titanic.html#encoder-les-donn√©es-imput√©es-ou-transform√©es.",
    "href": "docs/notebooks/titanic.html#encoder-les-donn√©es-imput√©es-ou-transform√©es.",
    "title": "Prediction de la survie d‚Äôun individu sur le Titanic üö¢",
    "section": "",
    "text": "A partir de cette analyse rapide, on va proposer les transformations suivantes:\n\nAge: il nous faut traiter les Null, on impute √† la moyenne m√™me s‚Äôil y a mieux √† faire‚Ä¶\nEmbarked: il a 2 valeurs manquantes qu‚Äôon ajoute √† la valeur la plus fr√©quente S\nFare : m√™me sort que Age on impute √† la moyenne\nhasCabin : Le nombre de Null √©tant importante on va ajouter la variable 1 ou 0 pour ne retenir que si la personne avait une cabine ou non\n\n::: {#cell-19 .cell _cell_guid=‚Äòb954644f-19d5-4edc-acc8-cf943a58534b‚Äô _uuid=‚Äò74d6076bd9236daf2cefd6c32b79119f6437923d‚Äô tags=‚Äò[]‚Äô execution_count=49}\n# Voila nos donn√©es d'apprentissage\nTrainingData.head()\n\n\n\n\n\n\n\n\n\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n:::\n\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nnumeric_features=[\"Age\", \"Fare\"]\ncategorical_features=[\"Embarked\", \"Sex\"]\n\nnumeric_transformer = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),\n(\"scaler\", MinMaxScaler()),])\n\ncategorical_transformer = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),(\"onehot\", OneHotEncoder()),])\n\n\npreprocessor = ColumnTransformer(\ntransformers=[\n(\"Preprocessing numerical\", numeric_transformer, numeric_features),\n(\n\"Preprocessing categorical\",\ncategorical_transformer,\ncategorical_features,\n),\n        ]\n    )\n\n\npipe = Pipeline(\n        [\n            (\"preprocessor\", preprocessor),\n            (\"classifier\", RandomForestClassifier(n_estimators=20)),\n        ]\n    )\npipe\n\nPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('Preprocessing numerical',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   MinMaxScaler())]),\n                                                  ['Age', 'Fare']),\n                                                 ('Preprocessing categorical',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder())]),\n                                                  ['Embarked', 'Sex'])])),\n                ('classifier', RandomForestClassifier(n_estimators=20))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.¬†¬†Pipeline?Documentation for PipelineiNot fittedPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('Preprocessing numerical',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   MinMaxScaler())]),\n                                                  ['Age', 'Fare']),\n                                                 ('Preprocessing categorical',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder())]),\n                                                  ['Embarked', 'Sex'])])),\n                ('classifier', RandomForestClassifier(n_estimators=20))]) ¬†preprocessor: ColumnTransformer?Documentation for preprocessor: ColumnTransformerColumnTransformer(transformers=[('Preprocessing numerical',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', MinMaxScaler())]),\n                                 ['Age', 'Fare']),\n                                ('Preprocessing categorical',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot', OneHotEncoder())]),\n                                 ['Embarked', 'Sex'])]) Preprocessing numerical['Age', 'Fare'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='median') ¬†MinMaxScaler?Documentation for MinMaxScalerMinMaxScaler() Preprocessing categorical['Embarked', 'Sex'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='most_frequent') ¬†OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder() ¬†RandomForestClassifier?Documentation for RandomForestClassifierRandomForestClassifier(n_estimators=20) \n\n\nOn split notre dataset d‚Äôapprentisage pour faire de la validation crois√©e une partie pour apprendre une partie pour regarder le score.\nPrenons arbitrairement 10% du dataset en test et 90% pour l‚Äôapprentissage.\n::: {#cell-23 .cell _cell_guid=‚Äòb768a96d-8f55-440f-b268-26fb613acc59‚Äô _uuid=‚Äòdfcfa465aa94260c2db0a6c87c9dea05cc0c45de‚Äô tags=‚Äò[]‚Äô execution_count=52}\ny = TrainingData[\"Survived\"]\nX = TrainingData.drop(\"Survived\", axis = 'columns')\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\npd.concat([X_train, y_train]).to_csv(\"train.csv\")\npd.concat([X_test, y_test]).to_csv(\"test.csv\")\n:::\n\njetonapi = \"$trotskitueleski1917\""
  }
]